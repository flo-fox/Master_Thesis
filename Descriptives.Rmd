---
author: "Florian Fox"
date: "`r Sys.Date()`"
title: 'Master Thesis: A Causal Test of the Law of 1/n and its Mechanisms -- Descriptive Statistics'
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
---

# Introduction

Note: Since this script serves as exploratory data analysis with respect to the research question, I use the `data` data set, i. e. the data set running until 2021. In the paper, I only use data until 2014. For the LaTeX export, I obviously limit the data set to the data used in the analysis scripts.


# Load data and packages

```{r Packages}
library(tidyverse)
library(haven)
library(reshape2)
library(ggcorrplot)
library(xtable)
source("functions/functions.R")
```

```{r Data}
data <-
  readRDS("data/gemeinderatswahlen_alldata.rds")
thresholds <- haven::read_stata("data/All_discs.dta")
```

```{r}
# similar data set definition as in "Analysis.Rmd"
d_rdd_bivariate <- data %>%
  select(ln_gross_expenditure_pc, total_seats, inhabs_rel_to_cutoff, above_cutoff, inhabitants_treshold_factor, inhabitants_treshold, year, ags, election_year, state, closest, clean_disc_acc_Höhmann, clean_disc_acc_to_my_research) %>%
  drop_na(ln_gross_expenditure_pc, total_seats, inhabs_rel_to_cutoff) %>%
  # Repeat (bandwidth) window calculation for data subsets
  mutate(
    closest = base::rank(abs(inhabs_rel_to_cutoff), ties.method = "last"),
    closest = closest/max(closest),
  )
d_rdd_bivariate2 <- data %>%
  select(ln_gross_expenditure_pc, total_seats, inhabs_rel_to_cutoff, above_cutoff, inhabitants_treshold_factor, inhabitants_treshold, year, ags, election_year, state, closest, clean_disc_acc_Höhmann, clean_disc_acc_to_my_research, by_law_seats) %>% # add by_law_seats here
  drop_na(ln_gross_expenditure_pc, total_seats, inhabs_rel_to_cutoff)
d_rdd <- data %>%
  select(ln_gross_expenditure_pc, total_seats, inhabs_rel_to_cutoff, above_cutoff, closest,
         inhabitants_treshold_factor, inhabitants_treshold, year, ags, state,
         inh_tot, pop_over65, unempl_rate, total_area_ha,
         share_working_age, kreisfreie_stadt, stadt, years_since_last_elec) %>%
  drop_na() %>%
  # Repeat (bandwidth) window calculation for data subsets
  mutate(
    closest = base::rank(abs(inhabs_rel_to_cutoff), ties.method = "last"),
    closest = closest/max(closest),
  )
```

```{r Options}
options(scipen = 20)
theme_set(theme_minimal())
```



# First look at the data

```{r First look}
glimpse(data)
```

# Univariate statistics

## NAs

```{r}
data %>%
  summarize(across(.cols = everything(),
                   .fns = ~sum(is.na(.))/n()
                   ))
data %>%
  group_by(state) %>%
  summarize(across(.cols = everything(),
                   .fns = ~sum(is.na(.))/n()
                   ))
data %>%
  group_by(year) %>%
  summarize(across(.cols = everything(),
                   .fns = ~sum(is.na(.))/n()
                   ))
data %>%
  group_by(state, year) %>%
  summarize(across(.cols = everything(),
                   .fns = ~sum(is.na(.))/n()
                   ))
```


## Numeric variables

```{r Univariate stats}
dim(data)
data %>%
  summarize(
    across(
      where(is.numeric),
      summarize2
    )
  ) %>%
  mutate(Stat = sum_stats,
         .before = No)
```


## Export to LaTeX

Exporting ta table of descriptive univariate statistics to LaTeX to use it in the paper.

```{r}
# Bivariate RDD data
d_rdd_bivariate_summary <- d_rdd_bivariate %>%
  select(ln_gross_expenditure_pc, total_seats, above_cutoff, inhabs_rel_to_cutoff,
         year, inhabitants_treshold) %>%
  # mutate(across(where(is.factor),
  #               as.numeric)) %>% 
  summarize(across(everything(), summarize2)) %>%
  mutate(Stat = sum_stats,
         .before = 1) %>%
  pivot_longer(-Stat, names_to = "Statistic") %>%
  pivot_wider(names_from = Stat, values_from = value) #%>%
  # mutate(Data_Set2 = "RDD without controls",
  #        .before = 1)
# Multivariate RDD data
d_rdd_multivariate_summary <- d_rdd %>%
  select(ln_gross_expenditure_pc, total_seats, above_cutoff, inhabs_rel_to_cutoff,
         year, inhabitants_treshold, inh_tot, share_working_age, pop_over65, unempl_rate, total_area_ha,
         kreisfreie_stadt, stadt, years_since_last_elec
         ) %>%
  mutate(across(where(is.factor),
                ~as.numeric(.)-1)) %>% 
  summarize(across(everything(), summarize2)) %>%
  mutate(Stat = sum_stats,
         .before = 1) %>% 
  pivot_longer(-Stat, names_to = "Statistic") %>%
  pivot_wider(names_from = Stat, values_from = value) #%>% 
  # mutate(Data_Set2 = "RDD with controls",
  #        .before = 1)
# Potentially heterogeneity-inducing variables
d_rdd_het_summary <- data %>%
  drop_na(ln_gross_expenditure_pc, total_seats, inhabs_rel_to_cutoff) %>%
  select(ln_gross_revenue_pc, ln_net_expenditure_pc,
         #contains("revenue"),
         ward_elections, const_typ_sueddt, ends_with("mayor"),
         no_parties_in_parliament, parties_in_parliament_hhi,
         absolute_majority, cdu_csu_majority, spd_majority, waehlergruppen_majority,
         starts_with("ln_expenditure"),
         female_share_council, female_share_largest_party,
         #kreisfreie_stadt, stadt
         ) %>%
  mutate(across(where(is.factor),
                ~as.numeric(.)-1)) %>% 
  summarize(across(everything(), summarize2)) %>%
  mutate(Stat = sum_stats,
         .before = 1) %>% 
  pivot_longer(-Stat, names_to = "Statistic") %>%
  pivot_wider(names_from = Stat, values_from = value) #%>%
  # mutate(Data_Set2 = "Potential heterogeneity-inducing variables",
  #        .before = 1)
# Tie it up
univar_descriptives <-
  bind_rows(d_rdd_bivariate_summary, d_rdd_multivariate_summary, d_rdd_het_summary) %>%
  select(!c(`No of unique values`, `No of NA`)) %>%
  mutate(
    Statistic = case_when(
      Statistic == "ln_gross_expenditure_pc" ~ "Ln of gross expenditure p. c.",
      Statistic == "total_seats" ~ "Council size",
      Statistic == "above_cutoff" ~ "Above cutoff (dummy, instrument)",
      Statistic == "inhabs_rel_to_cutoff" ~ "Running variable (inhabitants relative to thresholds)",
      #`Population (for coun. size)` = exact_pop,
      Statistic == "inhabitants_treshold" ~ "Council size population thresholds",
      Statistic == "inh_tot" ~ "Population (as of 12-31)",
      Statistic == "share_working_age" ~ "Share of working-age population",
      Statistic == "pop_over65" ~ "Share of poplation aged > 65 years",
      Statistic == "unempl_rate" ~ "Unemployment rate",
      Statistic == "total_area_ha" ~ "Total area in ha",
      Statistic == "kreisfreie_stadt" ~ "Independent large city (dummy)",
      Statistic == "stadt" ~ "City (dummy)",
      Statistic == "years_since_last_elec" ~ "Years since last election",
      Statistic == "ln_gross_revenue_pc" ~ "Ln of gross revenue p. c.",
      Statistic == "ln_net_expenditure_pc" ~ "Ln of net expenditure p. c.",
      #Statistic == "ln_revenue_administrative_pc" ~ "Ln of ",
      #"ln_revenue_admin_taxes_pc"            "ln_revenue_admin_transfers_pc"
      #"ln_revenue_admin_chargesfees_pc"      "ln_revenue_capital_pc"
      #"ln_revenue_capital_charges_pc"        "ln_revenue_capital_allocations_pc"
      #"ln_revenue_capital_loans_pc"          "ln_tax_prop_a_revenue_pc"
      Statistic == "ward_elections" ~ "Ward elections (dummy)",
      Statistic == "const_typ_sueddt" ~ "Southern-German type local constitution (dummy)",
      Statistic == "cdu_csu_mayor" ~ "CDU/CSU mayor (dummy, BY only)",
      Statistic == "spd_mayor" ~ "SPD mayor (dummy, BY only)",
      Statistic == "no_parties_in_parliament" ~ "Number of parties in council (NW, BW, BY, SL, MV, SN)",
      Statistic == "parties_in_parliament_hhi" ~ "Number of parties in council by HHI (NW, BW, BY, SL, MV, SN)",
      Statistic == "absolute_majority" ~ "Absolute majority (dummy, NW, BW, BY, SL, MV, SN)",
      Statistic == "cdu_csu_majority" ~ "Absolute CDU/CSU majority (dummy, NW, BW, BY, SL, MV, SN)",
      Statistic == "spd_majority" ~ "Absolute SPD majority (dummy, NW, BW, BY, SL, MV, SN)",
      Statistic == "waehlergruppen_majority" ~ "Absolute majority by independent election group (dummy, BY only)",
      Statistic == "ln_expenditure_administrative_pc" ~ "Ln of administrative expenditure p. c.",
      Statistic == "ln_expenditure_admin_personel_pc" ~ "Ln of personnel expenditure p. c.", #admin
      Statistic == "ln_expenditure_adminoperating_pc" ~ "Ln of operating expenditure p. c.", #admin
      Statistic == "ln_expenditure_capital_pc" ~ "Ln of capital expenditure p. c.",
      Statistic == "ln_expenditure_capital_loans_pc" ~ "Ln of loan expenditure p. c.", #capital
      Statistic == "ln_expenditure_capital_prop_inv_pc" ~ "Ln of property investment expenditure p. c.", #capital
      Statistic == "female_share_council" ~ "Female share in council (SH, BW, BY, SA, TH)",
      Statistic == "female_share_largest_party" ~ "Female share in largest council party (BW, BY only)",
      TRUE ~ paste(toupper(substr(Statistic, 1, 1)), substr(Statistic, 2, nchar(Statistic)), sep="")
    )
  ) %>%
  mutate(n = trimws(format(n, big.mark = ",") ) ) %>%
  add_row(Statistic = "RDD without controls", .before = 1) %>%
  add_row(Statistic = "RDD with controls", .before = 8) %>%
  add_row(Statistic = "Potentially heterogeneity-inducing variables/Potential mechanisms", .before = 23)
# Maybe add states whose valid values there are for each variable
univar_descriptives
# Export
print(xtable::xtable(univar_descriptives, digits = c(rep(2, times = 9), 0)),
      file = "tables/descriptives.tex",
      booktabs = TRUE, floating = FALSE,
      include.rownames = FALSE)
```

Further (descriptive) information mentioned in the paper:

Correlation of Bavarian council size:

```{r}
cor(data$total_seats, data$total_seats_24_y_ago, use = "pairwise.complete.obs")
```

Distance between population (cutoff) date for determining council size and the actual election date:

```{r}
summary(data$time_elec_pop_diff)
```




## Factors


```{r}
data %>%
  select(-where(is.numeric), -starts_with("ags"), -town) %>%
  sapply(., function(x) table(x, useNA = "always"))
```

# Bivariate descriptive statistics



Display correlation between standard council size (as determined (by me) by council size) with actual number of seats. (On the overall sample `data`:) Especially weak in Baden-Württemberg, North-Rhine Westphalia, and Saxony. Strong in Saarland (sharp design here), Thuringia, and Brandenburg (though few data points here).

```{r, rows.print=15}
data %>%
  group_by(state) %>%
  summarize(n = n(), seat_cor = cor(total_seats, by_law_seats, use = "pairwise.complete.obs")) %>%
  arrange(seat_cor)
# Main data set used in analysis
d_rdd_bivariate2 %>%
  group_by(state) %>%
  summarize(n = n(), seat_cor = cor(total_seats, by_law_seats, use = "pairwise.complete.obs")) %>%
  arrange(seat_cor)
cor(d_rdd_bivariate2$total_seats, d_rdd_bivariate2$by_law_seats, use = "pairwise.complete.obs")
# Main data set used in analysis & close to cutoffs
d_rdd_bivariate2 %>%
  filter(closest <= 0.1) %>%
  group_by(state) %>%
  summarize(n = n(), seat_cor = cor(total_seats, by_law_seats, use = "pairwise.complete.obs")) %>%
  arrange(seat_cor)
cor(d_rdd_bivariate2 %>% filter(closest <= 0.1) %>% pull(total_seats),
    d_rdd_bivariate2 %>% filter(closest <= 0.1) %>% pull(by_law_seats),
    use = "pairwise.complete.obs")
```


# Thresholds

## Unweighted

Unweighted, that is all thresholds found in the legal documents.

Prepare data set, i. e. use only data from states also used in analysis downstream.

```{r}
th <- thresholds %>%
  select(!starts_with("lag")) %>%
  filter(!(state %in% c("03", "12"))) %>% # No data on these two
  filter(state != "13") %>% # Höhmann: No data
  arrange(state)
```

Equality of my research results to Höhmann (2017):

```{r}
# Total:
th %>%
  summarize(
    sum_differences = sum(clear_disc_acc_Höhmann != clear_disc_acc_to_my_research, na.rm = TRUE),
    share_differences = sum(clear_disc_acc_Höhmann != clear_disc_acc_to_my_research, na.rm = TRUE) / n()
    ) %>%
  arrange(-share_differences)
# For each state:
th %>%
  group_by(state) %>%
  summarize(
    sum_differences = sum(clear_disc_acc_Höhmann != clear_disc_acc_to_my_research, na.rm = TRUE),
    share_differences = sum(clear_disc_acc_Höhmann != clear_disc_acc_to_my_research, na.rm = TRUE) / n()
    ) %>%
  arrange(-share_differences)
```

Show cases where I think of threshold as unconfounded but Höhmann does not:

```{r}
th %>% filter(clear_disc_acc_Höhmann < clear_disc_acc_to_my_research)
```

The Hessian threshold is not a real difference to Höhmann as the confounded policy was only introduced in 2014.

Where am I more "conservative" in designating thresholds as confounded?

```{r}
# Total:
th %>%
  summarize(
    sum_differences = sum(clear_disc_acc_Höhmann < clear_disc_acc_to_my_research, na.rm = TRUE),
    share_differences = sum(clear_disc_acc_Höhmann < clear_disc_acc_to_my_research, na.rm = TRUE) / n()
    ) %>%
  arrange(-share_differences)
# For each state:
th %>%
  group_by(state) %>%
  summarize(
    sum_differences = sum(clear_disc_acc_Höhmann < clear_disc_acc_to_my_research, na.rm = TRUE),
    share_differences = sum(clear_disc_acc_Höhmann < clear_disc_acc_to_my_research, na.rm = TRUE) / n()
    ) %>%
  arrange(-share_differences)
```

## Weighted

Use data set used for bivariate RDDs:

```{r}
# Total:
d_rdd_bivariate %>%
  summarize(
    sum_differences = sum(clean_disc_acc_Höhmann != clean_disc_acc_to_my_research, na.rm = TRUE),
    share_differences = sum(clean_disc_acc_Höhmann != clean_disc_acc_to_my_research, na.rm = TRUE) / n()
    ) %>%
  arrange(-share_differences)
# For each state:
d_rdd_bivariate %>%
  group_by(state) %>%
  summarize(
    sum_differences = sum(clean_disc_acc_Höhmann != clean_disc_acc_to_my_research, na.rm = TRUE),
    share_differences = sum(clean_disc_acc_Höhmann != clean_disc_acc_to_my_research, na.rm = TRUE) / n()
    ) %>%
  arrange(-share_differences)
```

Confounded/nonconfounded thresholds (unweighted):

```{r}
# Total -- confounded:
th %>%
  summarize(
    sum_confounded = sum(clear_disc_acc_to_my_research == 0, na.rm = TRUE),
    #share_confounded = sum_confounded / n(), # does not add up to 100 %, maybe b/c of missings
    sum_nonconfouned = sum(clear_disc_acc_to_my_research == 1, na.rm = TRUE),
    #share_nonconfouned = sum_nonconfouned / n(),
    sum_confounded_Hohm = sum(clear_disc_acc_Höhmann == 0, na.rm = TRUE),
    #share_confounded_Hohm = sum_confounded_Hohm / n(),
    sum_nonconfouned_Hohm = sum(clear_disc_acc_Höhmann == 1, na.rm = TRUE),
    #share_nonconfouned_Hohm = sum_nonconfouned_Hohm / n()
    ) %>%
  arrange(-sum_confounded)
# For each state -- confounded:
th %>%
  group_by(state) %>%
  summarize(
    sum_confounded = sum(clear_disc_acc_to_my_research == 0, na.rm = TRUE),
    #share_confounded = sum_confounded / n(),
    sum_nonconfouned = sum(clear_disc_acc_to_my_research == 1, na.rm = TRUE),
    #share_nonconfouned = sum_nonconfouned / n(),
    sum_confounded_Hohm = sum(clear_disc_acc_Höhmann == 0, na.rm = TRUE),
    #share_confounded_Hohm = sum_confounded_Hohm / n(),
    sum_nonconfouned_Hohm = sum(clear_disc_acc_Höhmann == 1, na.rm = TRUE),
    #share_nonconfouned_Hohm = sum_nonconfouned_Hohm / n()
    ) %>%
  arrange(-sum_confounded)
```



# Investigating covariate imbalance

Three RDD covariates have been shown to have a statistically significant jump at the threshold. Dummy "kreisfreie_stadt" and the share of population of working aged > 65 jump positively, the population share of working-age people jumps negatively.

```{r}
d_rdd_balance_test <- data %>%
  select(
    ln_gross_expenditure_pc, total_seats, inhabs_rel_to_cutoff, above_cutoff,
    inhabitants_treshold_factor, inhabitants_treshold, year, ags, election_year, state, # standard variables
    inh_tot, pop_over65, unempl_rate, total_area_ha,
    share_working_age, kreisfreie_stadt, stadt, lag_total_seats # Balance test variables
    ) %>%
  drop_na(ln_gross_expenditure_pc, total_seats, inhabs_rel_to_cutoff) %>%
  mutate(across(c(kreisfreie_stadt, stadt), ~ as.numeric(.)-1))
```
```{r}
d_rdd_balance_test %>%
  select(-c(inhabitants_treshold_factor, year, ags)) %>%
  cor(., use = "pairwise.complete.obs") %>%
  ggcorrplot::ggcorrplot(type = "lower", lab = TRUE, digits = 1)
d_rdd_balance_test %>%
  select(kreisfreie_stadt, share_working_age, pop_over65) %>%
  cor(., use = "pairwise.complete.obs") %>%
  ggcorrplot::ggcorrplot(type = "lower", lab = TRUE)
```



```{r}

```

