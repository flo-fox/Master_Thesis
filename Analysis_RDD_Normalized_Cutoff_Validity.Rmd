---
author: "Florian Fox"
date: "`r Sys.Date()`"
title: 'Master Thesis: A Causal Test of the Law of 1/n and its Mechanisms -- Analysis: RDD, Normalized Cutoff, Checking the Validity'
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
---

# Load data and packages

```{r Packages}
time <- Sys.time()
library(tidyverse)
library(fixest)
library(rdrobust)
#library(rdmulti)
library(rddensity)
library(rdd) # For the McCrary (2008) test
library(xtable)
library(scales)
library(janitor)
source("functions/functions.R")
```

```{r Data}
data <-
  readRDS("data/gemeinderatswahlen_alldata.rds") %>%
  mutate(
    year = as.factor(year),
    ags = as.factor(ags)
  )
```


Generating different data sets:

```{r}
# d_bivariate <- data %>%
#   select(ln_gross_expenditure_pc, total_seats, ags, year, state) %>% drop_na()
# d_bivariate_iv <- data %>%
#   select(ln_gross_expenditure_pc, total_seats, ags, year, total_seats_24_y_ago) %>% drop_na()
d_rdd_bivariate <- data %>%
  select(ln_gross_expenditure_pc, total_seats, inhabs_rel_to_cutoff, above_cutoff, inhabitants_treshold_factor, inhabitants_treshold, year, ags, election_year, state, closest, clean_disc_acc_HÃ¶hmann, clean_disc_acc_to_my_research) %>%
  drop_na(ln_gross_expenditure_pc, total_seats, inhabs_rel_to_cutoff) %>%
  # Repeat (bandwidth) window calculation for data subsets
  mutate(
    closest = base::rank(abs(inhabs_rel_to_cutoff), ties.method = "last"),
    closest = closest/max(closest),
  )

# d_controls <- data %>%
#   select(ln_gross_expenditure_pc, total_seats, ags, year, inh_tot, pop_over65, unempl_rate, total_area_ha,
#     share_working_age, kreisfreie_stadt, stadt, years_since_last_elec, state) %>%
#   drop_na()
# d_controls_iv <- data %>%
#   select(ln_gross_expenditure_pc, total_seats, ags, year, total_seats_24_y_ago, inh_tot, pop_over65,
#          unempl_rate, total_area_ha, share_working_age, kreisfreie_stadt, stadt,
#          years_since_last_elec) %>%
#   drop_na()
d_rdd <- data %>%
  select(ln_gross_expenditure_pc, total_seats, inhabs_rel_to_cutoff, above_cutoff, closest,
         inhabitants_treshold_factor, year, ags, state,
         inh_tot, pop_over65, unempl_rate, total_area_ha,
         share_working_age, kreisfreie_stadt, stadt, years_since_last_elec) %>%
  drop_na() %>%
  # Repeat (bandwidth) window calculation for data subsets
  mutate(
    closest = base::rank(abs(inhabs_rel_to_cutoff), ties.method = "last"),
    closest = closest/max(closest),
  )
d_ttest <- data %>%
  select(ln_gross_expenditure_pc, inhabs_rel_to_cutoff) %>% drop_na()
```



# Density tests

I am only using election years in order to avoid multiple observations on the running variable (also for the `rddensity` check).

```{r}
dens_test_d_rdd_bivariate <- d_rdd_bivariate %>%
  filter(election_year == 1 | year == 2002)
```

## McCrary (2008) Sorting test

McCrary test for all states pooled (with running variable values occuring multiple times):
```{r}
rdd::DCdensity(runvar = data$inhabs_rel_to_cutoff, cutpoint = 0, plot = TRUE, verbose = TRUE)
```

```{r}
rdd::DCdensity(runvar = dens_test_d_rdd_bivariate$inhabs_rel_to_cutoff, cutpoint = 0, plot = TRUE, verbose = TRUE)
```


Export plot:
```{r}
pdf(file = "plots/mccrary.pdf", width = 7, height = 7*9/16)
rdd::DCdensity(runvar = dens_test_d_rdd_bivariate$inhabs_rel_to_cutoff, cutpoint = 0, plot = TRUE, verbose = TRUE)
title(xlab = "Running variable (population relative to thresholds)")
abline(v=0)
dev.off()
```

The test for the overall data is significant (i. e. there is a jump at the threshold). But this may be due to almost all values of the running variable occuring multiple times (given the nature of the data set). Hence, the "real" test on the data set is not statistically significant any more.


## `rddensity` discontinuity test

```{r}
rddensity_disc_test <- rddensity::rddensity(X = dens_test_d_rdd_bivariate$inhabs_rel_to_cutoff, c = 0)
summary(rddensity_disc_test)
p <- rdplotdensity_with_theme(rddensity_disc_test, X = dens_test_d_rdd_bivariate$inhabs_rel_to_cutoff, xlabel = "Running variable (population relative to thresholds)")
```

Export plot
```{r}
pdf(file = "plots/rddensity.pdf", width = 6, height = 6*9/16)
p
dev.off()
rm(p)
```

## Testing for sorting in different entities, time periods, thresholds...

McCrary and `rddensity` tests for each state separately.

- McCrary: HE & TH have (positive) significant jumps at the cutoff.
- `rddensity`: BW & SA show signs of significant sorting at the cutoff, positively and negatively, respectively.

```{r}
all_states <- dens_test_d_rdd_bivariate %>%
  distinct(state) %>%
  filter(state != 3 & state != 12 & state != 13 & state != 15) %>% # Remove state with no/too few obs
  pull()
jump_mccrary <- list()
p_value_mccrary <- list()
jump_rddensity <- list()
p_value_rddensity <- list()
state <- list()
for (i in all_states){
  df_subset <- dens_test_d_rdd_bivariate %>% filter(state == i) %>% drop_na(inhabs_rel_to_cutoff)
  state[i] <- i
  out_mccrary <- rdd::DCdensity(runvar = df_subset$inhabs_rel_to_cutoff, cutpoint = 0, plot = FALSE, ext.out = TRUE)
  jump_mccrary[i] <- out_mccrary$theta
  p_value_mccrary[i] <- out_mccrary$p
  out_rddensity <- rddensity::rddensity(X = df_subset$inhabs_rel_to_cutoff)
  jump_rddensity[i] <- out_rddensity$hat$diff
  p_value_rddensity[i] <- out_rddensity$test$p_jk
}
sorting <- tibble(state, jump_mccrary, p_value_mccrary, jump_rddensity, p_value_rddensity) %>%
  unnest() %>%
  arrange(p_value_rddensity)
sorting
rm(all_states, df_subset, jump_mccrary, jump_rddensity, out_mccrary, out_rddensity, p_value_mccrary, p_value_rddensity, state)
```

McCrary and `rddensity` tests for each year separately:

- McCrary: No significant discontinuities here.
- `rddensity`: 2003 and 2004 (the latter was an important election year on the local level) show signs of sorting to the right at the 10% level.


```{r}
all_years <- dens_test_d_rdd_bivariate %>%
  distinct(year) %>%
  arrange(year) %>%
  pull()
year <- list()
jump_mccrary <- list()
p_value_mccrary <- list()
jump_rddensity <- list()
p_value_rddensity <- list()
for (i in all_years){
  df_subset <- dens_test_d_rdd_bivariate %>% filter(year == i) %>% drop_na(inhabs_rel_to_cutoff)
  year[i] <- i
  out_mccrary <- rdd::DCdensity(runvar = df_subset$inhabs_rel_to_cutoff, cutpoint = 0, plot = FALSE, ext.out = TRUE)
  jump_mccrary[i] <- out_mccrary$theta
  p_value_mccrary[i] <- out_mccrary$p
  out_rddensity <- rddensity::rddensity(X = df_subset$inhabs_rel_to_cutoff)
  jump_rddensity[i] <- out_rddensity$hat$diff
  p_value_rddensity[i] <- out_rddensity$test$p_jk
  #print(paste0("McCrary -- Year: ", i, ", jump: ", out1$theta, ", p value: ", out1$p, ", n: ", length(df_subset$inhabs_rel_to_cutoff)))
  #print(paste0("rddensity -- Year: ", i, ", jump: ", out2$hat$diff, ", p value: ", out2$test$p_jk, ", n: ", length(df_subset$inhabs_rel_to_cutoff)))
}
sorting <- tibble(year, jump_mccrary, p_value_mccrary, jump_rddensity, p_value_rddensity) %>%
  unnest() %>%
  arrange(p_value_rddensity)
sorting
rm(all_years, df_subset, jump_mccrary, jump_rddensity, out_mccrary, out_rddensity, p_value_mccrary, p_value_rddensity, year)
```

Testing at every threshold separately:

- McCrary test: 300, 2,000, and 10,000 significant at least at the 10 % significance level.
- `rddensity` reveals sorting to the left at the 15,000 threshold.

```{r}
all_th <- dens_test_d_rdd_bivariate %>%
  filter(inhabitants_treshold <= 30000 | inhabitants_treshold == 50000 |
           inhabitants_treshold == 100000 | inhabitants_treshold == 150000) %>%
  # Test works only for those values
  distinct(inhabitants_treshold) %>%
  arrange(inhabitants_treshold) %>%
  pull()
threshold <- list()
state <- list()
jump_mccrary <- list()
p_value_mccrary <- list()
jump_rddensity <- list()
p_value_rddensity <- list()
for (i in all_th){
  df_subset <- dens_test_d_rdd_bivariate %>%
    filter(inhabitants_treshold == i) %>%
    drop_na(inhabs_rel_to_cutoff)
  state[i] <- unique(df_subset$state) %>% paste(collapse = ",")
  threshold[i] <- i
  out_mccrary <- rdd::DCdensity(runvar = df_subset$inhabs_rel_to_cutoff, cutpoint = 0, plot = FALSE, ext.out = TRUE)
  jump_mccrary[i] <- out_mccrary$theta
  p_value_mccrary[i] <- out_mccrary$p
  out_rddensity <- rddensity::rddensity(X = df_subset$inhabs_rel_to_cutoff)
  jump_rddensity[i] <- out_rddensity$hat$diff
  p_value_rddensity[i] <- out_rddensity$test$p_jk
}
sorting <- tibble(threshold, state, jump_mccrary, p_value_mccrary, jump_rddensity, p_value_rddensity) %>%
  unnest() %>%
  arrange(p_value_rddensity)
sorting
rm(all_th, df_subset, jump_mccrary, jump_rddensity, out_mccrary, out_rddensity, p_value_mccrary, p_value_rddensity, state, threshold)
```

### Varying bandwidths

Limiting data set to observations x % closest to the cutoff but maintaining data-driven bandwidth selection:
```{r}
bandwidths <- seq(0.025, 0.3, 0.025)
jump_mccrary <- list()
p_value_mccrary <- list()
jump_rddensity <- list()
p_value_rddensity <- list()
n <- list()
for (i in 1:length(bandwidths)){
  df_subset <- dens_test_d_rdd_bivariate %>% filter(closest <= bandwidths[i])
  # Filtering not done 100 % correctly, see definition of dens_test_d_rdd_bivariate
  out_mccrary <- rdd::DCdensity(runvar = df_subset$inhabs_rel_to_cutoff, cutpoint = 0, plot = FALSE, ext.out = TRUE)
  jump_mccrary[i] <- out_mccrary$theta
  p_value_mccrary[i] <- out_mccrary$p
  out_rddensity <- rddensity::rddensity(X = df_subset$inhabs_rel_to_cutoff)
  jump_rddensity[i] <- out_rddensity$hat$diff
  p_value_rddensity[i] <- out_rddensity$test$p_jk
  n[i] <- length(df_subset$inhabs_rel_to_cutoff)
}
sorting <- tibble(bandwidths, jump_mccrary, p_value_mccrary, jump_rddensity, p_value_rddensity, n) %>%
  unnest() %>%
  arrange(p_value_rddensity)
sorting
rm(bandwidths, df_subset, jump_mccrary, jump_rddensity, n, out_mccrary, out_rddensity, p_value_mccrary, p_value_rddensity)
```

Using all observations in x % window, without further (data-driven) bandwidth selection:

```{r}
bandwidths <- seq(0.025, 0.3, 0.025)
jump_mccrary <- list()
p_value_mccrary <- list()
jump_rddensity <- list()
p_value_rddensity <- list()
n <- list()
bw <- 100
for (i in 1:length(bandwidths)){
  df_subset <- dens_test_d_rdd_bivariate %>% filter(closest <= bandwidths[i])
  # Filtering not done 100 % correctly, see definition of dens_test_d_rdd_bivariate
  out_mccrary <- rdd::DCdensity(runvar = df_subset$inhabs_rel_to_cutoff, cutpoint = 0, plot = FALSE, ext.out = TRUE, bw = bw)
  jump_mccrary[i] <- out_mccrary$theta
  p_value_mccrary[i] <- out_mccrary$p
  out_rddensity <- rddensity::rddensity(X = df_subset$inhabs_rel_to_cutoff, h = bw)
  jump_rddensity[i] <- out_rddensity$hat$diff
  p_value_rddensity[i] <- out_rddensity$test$p_jk
  n[i] <- length(df_subset$inhabs_rel_to_cutoff)
}
sorting <- tibble(bandwidths, jump_mccrary, p_value_mccrary, jump_rddensity, p_value_rddensity, n) %>%
  unnest() %>%
  arrange(p_value_rddensity)
sorting
rm(bandwidths, df_subset, jump_mccrary, jump_rddensity, n, out_mccrary, out_rddensity, p_value_mccrary, p_value_rddensity)
```

For both applications, the McCrary test consistently shows sorting, whereas the `rddensity` test is (with a single exception) unable to detect sorting. Puzzling...


### Placebo density tests

Placebo McCrary (2008) test: Even the placebo thresholds are statistically significant in many cases. Maybe the discontinuities above are just a matter of statistical power?
```{r}
# "Structured" approach
cuts <- seq(from = -(2+2/3), to = 2/3, by = 1/6) # Values chosen such that code does run
#length <- length(cuts)
cutoff <- list()
jump_mccrary <- list()
p_value_mccrary <- list()
out_rddensity <- list()
jump_rddensity <- list()
p_value_rddensity <- list()
for (i in 1:length(cuts)){
  cutoff[i] <- cuts[i]
  out_mccrary <- rdd::DCdensity(runvar = dens_test_d_rdd_bivariate$inhabs_rel_to_cutoff,
                              cutpoint = cuts[i], plot = FALSE, ext.out = TRUE)
  jump_mccrary[i] <- out_mccrary$theta
  p_value_mccrary[i] <- out_mccrary$p
  out_rddensity <- rddensity::rddensity(X = dens_test_d_rdd_bivariate$inhabs_rel_to_cutoff,
                                           c = cuts[i])
  jump_rddensity[i] <- out_rddensity$hat$diff
  p_value_rddensity[i] <- out_rddensity$test$p_jk
}
sorting <- tibble(cutoff, jump_mccrary, p_value_mccrary, jump_rddensity, p_value_rddensity) %>%
  unnest() %>%
  arrange(p_value_mccrary)
sorting
ggplot2::ggplot(sorting) + geom_histogram(aes(p_value_mccrary))
ggplot2::ggplot(sorting) + geom_histogram(aes(p_value_rddensity))
rm(cutoff, cuts, i, jump_rddensity, out_mccrary, out_rddensity, p_value_mccrary, p_value_rddensity)
```
```{r}
# "Random" approach
set.seed(234) # Value chosen such that rdd:DCdensity actually runs without error -> bias?
random_z_score <- rnorm(50)/2 # Neither randomly nor z-distributed, but roughly around my cutoff
cutoff <- list()
jump_mccrary <- list()
p_value_mccrary <- list()
out_rddensity <- list()
jump_rddensity <- list()
p_value_rddensity <- list()
for (i in 1:50){
  cutoff[i] <- random_z_score[i]
  out_mccrary <- rdd::DCdensity(runvar = dens_test_d_rdd_bivariate$inhabs_rel_to_cutoff,
                                       cutpoint = random_z_score[i], plot = FALSE, ext.out = TRUE)
  jump_mccrary[i] <- out_mccrary$theta
  p_value_mccrary[i] <- out_mccrary$p
  out_rddensity <- rddensity::rddensity(X = dens_test_d_rdd_bivariate$inhabs_rel_to_cutoff,
                               c = random_z_score[i])
  jump_rddensity[i] <- out_rddensity$hat$diff
  p_value_rddensity[i] <- out_rddensity$test$p_jk
}
sorting <- tibble(cutoff, p_value_mccrary, jump_rddensity, p_value_rddensity) %>%
  unnest() %>%
  arrange(cutoff)
sorting
ggplot2::ggplot(sorting) + geom_histogram(aes(p_value_mccrary))
ggplot2::ggplot(sorting) + geom_histogram(aes(p_value_rddensity))
rm(cutoff, i, jump_mccrary, jump_rddensity, out_mccrary, out_rddensity, p_value_mccrary, p_value_rddensity, random_z_score)
```
Strangely, the number of observations with p values smaller than 10 % is higher than one would expect, especially with the McCrary test. I do not have an explanation for this.


```{r}
rm(dens_test_d_rdd_bivariate, sorting)
```


# Balance tests

U. a. auch lagged treatment testen

Idea: Re-run RDD machinery with covariates as the dependent variable. There should be no discontinuities for the RDD to be valid. If there were, there would be sorting on observables around the thresholds. If there are not, we assume no sorting on observable and, in extension, no sorting on unobservables (which is not testable for obvious reasons).

Write wrapper function similar to the one from the robustness-check section:
```{r balance_test_wrapper}
balance_test_fe_model <- function(yy, ffuzzy = NULL, bbwselect = "mserd") {
  rdrobust::rdrobust(
    y = yy,
    x = d_rdd_bivariate$inhabs_rel_to_cutoff,
    fuzzy = ffuzzy,
    cluster = d_rdd_bivariate$inhabitants_treshold_factor,
    covs = model.matrix( ~ d_rdd_bivariate$inhabitants_treshold_factor + d_rdd_bivariate$year + d_rdd_bivariate$state),
    bwselect = bbwselect
  )
}
```
Create data set:
```{r}
d_rdd_balance_test <- data %>%
  select(
    ln_gross_expenditure_pc, total_seats, inhabs_rel_to_cutoff, above_cutoff,
    inhabitants_treshold_factor, inhabitants_treshold, year, ags, election_year, state, # standard variables
    inh_tot, pop_over65, unempl_rate, total_area_ha,
    share_working_age, kreisfreie_stadt, stadt, lag_total_seats # Balance test variables
    ) %>%
  drop_na(ln_gross_expenditure_pc, total_seats, inhabs_rel_to_cutoff) %>%
  mutate(across(c(kreisfreie_stadt, stadt), ~ as.numeric(.)-1))
  # group_by(ags) %>%
  # mutate(total_seats_lagged = dplyr::lag(total_seats, 5),
  #        across(c(kreisfreie_stadt, stadt), as.numeric)) %>% # create lagged treatment variable
  # ungroup()
```

Run balance test in both sharp and fuzzy design for non-dummy variables:
```{r rdd_fuzzy_balance_test, eval=FALSE}
# to do: remove eval=FALSE
rdd_balance_tests <-
  tibble(variable = "", method = "", bw_procedure = "", point_estimate = "", se = "", se_robust = "",
         ci_lower = "", ci_upper = "", p = "", bw = "", obs_below = "", obs_above = "") %>%
  mutate(across(4:last_col(), as.numeric))
bal_vars <- c("inh_tot", "pop_over65", "unempl_rate", "total_area_ha", "share_working_age", "kreisfreie_stadt", "stadt", "lag_total_seats")
for (i in bal_vars) {
  for (j in c("mserd", "cerrd")) {
  print(paste("Sharp,", i, j))
  rdd_bt <- balance_test_fe_model(yy = d_rdd_balance_test %>% pull(i),
                                  bbwselect = j)
  #summary(rdd_bt)
  rdd_balance_tests <- rdd_balance_tests %>%
    dplyr::add_row(
      variable = i,
      method = "sharp",
      bw_procedure = j,
      point_estimate = rdd_bt$coef[1],
      se = rdd_bt$se[1],
      se_robust = rdd_bt$se[3],
      ci_lower = rdd_bt$ci[3,1],
      ci_upper = rdd_bt$ci[3,2],
      p = rdd_bt$pv[3],
      bw = rdd_bt$bws[1,1],
      obs_below = rdd_bt$N_h[1],
      obs_above = rdd_bt$N_h[2]
  )
  print(paste("Fuzzy,", i, j))
  rdd_bt <- balance_test_fe_model(yy = d_rdd_balance_test %>% pull(i),
                                  ffuzzy =  d_rdd_balance_test$total_seats,
                                  bbwselect = j)
  #summary(rdd_bt)
  rdd_balance_tests <- rdd_balance_tests %>%
    dplyr::add_row(
      variable = i,
      method = "fuzzy",
      bw_procedure = j,
      point_estimate = rdd_bt$coef[1],
      se = rdd_bt$se[1],
      se_robust = rdd_bt$se[3],
      ci_lower = rdd_bt$ci[3,1],
      ci_upper = rdd_bt$ci[3,2],
      p = rdd_bt$pv[3],
      bw = rdd_bt$bws[1,1],
      obs_below = rdd_bt$N_h[1],
      obs_above = rdd_bt$N_h[2]
  )
  }
}
rdd_balance_tests <- rdd_balance_tests %>% drop_na()
save(rdd_balance_tests, file = "tables_robustness_checks/rdd_balance_tests.Rdata")
rm(bal_vars, i, rdd_bt)
```
```{r}
load(file = "tables_robustness_checks/rdd_balance_tests.Rdata")
rdd_balance_tests
```
Visualization of balance tests -- does not make much sense considering the large variation:
```{r, rdrobust_balance_test_viz, eval=FALSE}
df <- rdd_balance_tests %>%
  tidyr::drop_na() %>%
  filter(
    method == "fuzzy",
    #bw_procedure == "mserd",
    bw_procedure == "cerrd"
    ) #%>% 
  #mutate(effective_n = paste0("n=", trimws(format(effective_n, big.mark = ",") ) ) ) # add big mark
ggplot2::ggplot(df) +
  geom_point(aes(x = variable, y = point_estimate), size = 1.5, colour = ifelse(df$p <= 0.05, 2, 1)) +
  geom_errorbar(aes(x = variable, ymin = ci_lower, ymax = ci_upper),
                colour = ifelse(df$p <= 0.05, 2, 1),
                linetype = ifelse(df$p <= 0.05, 2, 1)) +
  # geom_text(aes(x = variable, y = ci_lower, label = effective_n),
  #           colour = ifelse(df$p <= 0.05, 2, 1), vjust = 1) +
  #scale_y_continuous(labels = scales::percent) +
  labs(x = "Covariates", y = "Jump at the threshold")
#ggsave(filename = "plots/rdrobust_balance_test.pdf", width = 6, height = 6*9/16)
rm(df)
```
Table of balance test regressions with fuzzy and cerred method:
```{r, rdrobust_balance_test_table}
# Correlations to test similarity of methods
cor(rdd_balance_tests %>% filter(method == "sharp") %>% pull(p),
    rdd_balance_tests %>% filter(method == "fuzzy") %>% pull(p))
cor(rdd_balance_tests %>% filter(bw_procedure == "mserd") %>% pull(p),
    rdd_balance_tests %>% filter(bw_procedure == "cerrd") %>% pull(p))
cor(rdd_balance_tests %>% filter(method == "fuzzy", bw_procedure == "mserd") %>% pull(p),
    rdd_balance_tests %>% filter(method == "fuzzy", bw_procedure == "cerrd") %>% pull(p))
cor(rdd_balance_tests %>% filter(method == "fuzzy", bw_procedure == "mserd") %>% pull(point_estimate),
    rdd_balance_tests %>% filter(method == "fuzzy", bw_procedure == "cerrd") %>% pull(point_estimate))
# Table
df <- rdd_balance_tests %>%
  mutate(across(where(is.numeric), ~ round(., digits = round_decimals))) %>%
  rowwise() %>%
  mutate(point_estimate = paste0(point_estimate, assign_stars(p)), .after = method) %>%
  mutate(ci = paste0("[", ci_lower, ", ", ci_upper, "]"), .before = p) %>%
  ungroup() %>%
  filter(method == "fuzzy", bw_procedure == "cerrd") %>%
  arrange(p) %>%
  select(-c(method, bw_procedure, se_robust, ci_lower, ci_upper, p)) %>%
  t() %>%
  tibble::as_tibble() %>%
  janitor::row_to_names(row_number = 1) %>%
  mutate(`Dependent variable` = c("Point estimate", "SE", "CI", "Bandwidth", "Obs. below", "Obs. above"),
         .before = 1) %>%
  dplyr::rename(`Population (as of 12-31)` = inh_tot, `Share of poplation aged > 65 years` = pop_over65, `Unemployment rate` = unempl_rate, `Total area in ha` = total_area_ha, `Share of working-age population` = share_working_age, `District-free city (dummy)` = kreisfreie_stadt, `City (dummy)` = stadt, `Lagged council size` = lag_total_seats)
df
print(
  xtable::xtable(
    df %>% select(1:4), # Only significant columns
    align = "llccc"
    ),
  file = "tables/rdd_balance_tests.tex",
  booktabs = TRUE,
  floating = FALSE,
  hline.after = c(-1, -1, 0, 3, nrow(df), nrow(df)),
  include.rownames = FALSE
)
# Appendix:
print(
  xtable::xtable(
    df %>% select(1, 5:last_col()), # Nonsignificant columns
    align = "llccccc"
    ),
  file = "tables/rdd_balance_tests_appendix.tex",
  booktabs = TRUE,
  floating = FALSE,
  hline.after = c(-1, -1, 0, 3, nrow(df), nrow(df)),
  include.rownames = FALSE
)
rm(df)
```



Alternative approach: Run t tests on both sides of the cutoff with values close to it.


# Concluding Remarks

For references, see the paper.

```{r}
Sys.time() - time
```
